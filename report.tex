% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Own Project Report: Predicting Organic Carbon in Soils},
  pdfauthor={Marcus Schmidt},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering

\title{Own Project Report: Predicting Organic Carbon in Soils}
\author{Marcus Schmidt}
\date{23/02/2021}

\begin{document}
\maketitle

\hypertarget{i-introduction}{%
\section{(I) INTRODUCTION}\label{i-introduction}}

\hypertarget{i-a-background-goal-data-set}{%
\subsection{(I a) Background, goal \& data
set}\label{i-a-background-goal-data-set}}

Soils are the basis of all agriculture. Organic carbon and its dynamics
plays a large role carbon sequestration and therefore helps regulate our
climate. The goal of this project is to predict soil organic carbon from
a large set of European soil data. The data set is from the LUCAS
initiative 2015 (\url{https://esdac.jrc.ec.europa.eu/projects/lucas})
and includes over 20,000 sampling points on land that is used in
different ways.

\hypertarget{i-b-data-set-download}{%
\subsection{(I b) Data set download}\label{i-b-data-set-download}}

The data set was requested online from the LUCAS initiative and the
author got permission to use it for this project. Out of the data set, I
created a *.Rdata file to be downloaded here:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{load}\NormalTok{(}\KeywordTok{url}\NormalTok{(}\StringTok{"https://github.com/ms{-}soil/ds{-}submission{-}soil/raw/main/eusoil.Rdata"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{i-c-data-set-structure}{%
\subsection{(I c) Data set structure}\label{i-c-data-set-structure}}

Let's take a peak at the datset, showing the variables included, the
dimension of the data set and a first look at the numbers and their
variable type:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{names}\NormalTok{(eusoil) }\CommentTok{\# variable names}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "Clay"        "Sand"        "Silt"        "pH.CaCl2."   "pH.H2O."    
##  [6] "EC"          "OC"          "CaCO3"       "P"           "N"          
## [11] "K"           "Elevation"   "Soil_Stones" "LC1"         "LC1_Desc"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dim}\NormalTok{(eusoil) }\CommentTok{\# data set dimensions}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 21859    15
\end{verbatim}

\newpage

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{as\_tibble}\NormalTok{(eusoil) }\CommentTok{\# overview of data structure}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 21,859 x 15
##     Clay  Sand  Silt pH.CaCl2. pH.H2O.    EC    OC CaCO3     P     N     K
##    <int> <int> <int>     <dbl>   <dbl> <dbl> <dbl> <int> <dbl> <dbl> <dbl>
##  1    NA    NA    NA       3.9    3.91  44.2  25.5     0  42.9   2.8  24.6
##  2    NA    NA    NA       3.1    3.91  46.4 504.      0 165.   19.9 460. 
##  3    NA    NA    NA       4.9    5.48  15.8  51.4     0  26.9   4.3 173. 
##  4    NA    NA    NA       3      3.76  26.9 470.      0 103.   16.1 313  
##  5    10    46    44       3.9    4.04  28.4  43.1     1   6.3   2.3  38.6
##  6    14    36    50       4.2    4.41  41.8  32.4     0   7.5   3.3  48  
##  7    18    35    46       4.9    5.13  32    21.1     1  12.4   2.1  36  
##  8    14    36    50       4      4.16  72.4  53.2     0  52.1   4.2 158. 
##  9    19    48    34       3.7    3.87  11.6  16       1   3.7   1    24.4
## 10     8    71    20       4      3.99  22.2  16       1   8.3   1.1  30  
## # ... with 21,849 more rows, and 4 more variables: Elevation <int>,
## #   Soil_Stones <int>, LC1 <chr>, LC1_Desc <chr>
\end{verbatim}

\hypertarget{ii-methods-analysis}{%
\section{(II) METHODS \& ANALYSIS}\label{ii-methods-analysis}}

\hypertarget{ii-a-data-preparation}{%
\subsection{(II a) Data preparation}\label{ii-a-data-preparation}}

Analysis was don with R version 4.0.3. Land use as a variable in the
data set is not straightforward. It is decoded in the LC1-variable, so
we detect the capital letter in the variable character string and assign
the respective land use from the data-set documentation, which can be
found at \url{https://github.com/ms-soil/ds-submission-soil}
(data-info.pdf). After this we remove the LC1-variable. We further check
whether there are any observations where organic carbon (OC) is missing
and take a look at how many observations we have for each land use. For
further analysis, land use will be turned into a factor.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{eusoil <{-}}\StringTok{ }\NormalTok{eusoil }\OperatorTok{\%>\%}\StringTok{ }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{landuse =} \KeywordTok{case\_when}\NormalTok{(}\KeywordTok{str\_detect}\NormalTok{(LC1, }\StringTok{"A"}\NormalTok{) }\OperatorTok{\textasciitilde{}}\StringTok{ "artif\_land"}\NormalTok{,}
                                                \KeywordTok{str\_detect}\NormalTok{(LC1, }\StringTok{"B"}\NormalTok{) }\OperatorTok{\textasciitilde{}}\StringTok{ "cropland"}\NormalTok{,}
                                                \KeywordTok{str\_detect}\NormalTok{(LC1, }\StringTok{"C"}\NormalTok{) }\OperatorTok{\textasciitilde{}}\StringTok{ "woodland"}\NormalTok{,}
                                                \KeywordTok{str\_detect}\NormalTok{(LC1, }\StringTok{"D"}\NormalTok{) }\OperatorTok{\textasciitilde{}}\StringTok{ "shrubland"}\NormalTok{,}
                                                \KeywordTok{str\_detect}\NormalTok{(LC1, }\StringTok{"E"}\NormalTok{) }\OperatorTok{\textasciitilde{}}\StringTok{ "grassland"}\NormalTok{,}
                                                \KeywordTok{str\_detect}\NormalTok{(LC1, }\StringTok{"F"}\NormalTok{) }\OperatorTok{\textasciitilde{}}\StringTok{ "bare\_land"}\NormalTok{,}
                                                \KeywordTok{str\_detect}\NormalTok{(LC1, }\StringTok{"G"}\NormalTok{) }\OperatorTok{\textasciitilde{}}\StringTok{ "water"}\NormalTok{,}
                                                \KeywordTok{str\_detect}\NormalTok{(LC1, }\StringTok{"H"}\NormalTok{) }\OperatorTok{\textasciitilde{}}\StringTok{ "wetland"}\NormalTok{)) }\OperatorTok{\%>\%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{{-}}\NormalTok{LC1)}

\KeywordTok{table}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(eusoil}\OperatorTok{$}\NormalTok{OC)) }\CommentTok{\# organic carbon data is available in all observations}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## FALSE 
## 21859
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# distribution of landuses}
\KeywordTok{table}\NormalTok{(eusoil}\OperatorTok{$}\NormalTok{landuse)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## artif_land  bare_land   cropland  grassland  shrubland      water    wetland 
##         50        604       8972       4751        846          6         49 
##   woodland 
##       6581
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# factorize landuse}
\NormalTok{eusoil <{-}}\StringTok{ }\NormalTok{eusoil }\OperatorTok{\%>\%}\StringTok{ }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{landuse =} \KeywordTok{as.factor}\NormalTok{(landuse))}
\end{Highlighting}
\end{Shaded}

\hypertarget{ii-b-variable-selection}{%
\subsection{(II b) Variable selection}\label{ii-b-variable-selection}}

We want to use a complete data set for our predictions, so we exclude
variables that are often missing. We can see it with the following code.
It yields that we are missing the texture variables (sand, silt, clay)
in over 80\% of cases.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# print availability for every variable}
\NormalTok{res <{-}}\StringTok{ }\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(}\KeywordTok{names}\NormalTok{(eusoil))) \{ }
  \KeywordTok{print}\NormalTok{(}\KeywordTok{table}\NormalTok{(}\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(eusoil[,i])))}
  \KeywordTok{print}\NormalTok{(}\KeywordTok{names}\NormalTok{(eusoil[i]))}
\NormalTok{\}}
\CommentTok{\# texture (the silt, sand and clay variables) are only available in a fraction of cases}
\CommentTok{\# see which fraction of the dataset misses texture}
\NormalTok{condition <{-}}\StringTok{ }\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(eusoil}\OperatorTok{$}\NormalTok{Clay)}
\KeywordTok{table}\NormalTok{(condition)[[}\DecValTok{1}\NormalTok{]]}\OperatorTok{/}\NormalTok{(}\KeywordTok{table}\NormalTok{(condition)[[}\DecValTok{1}\NormalTok{]] }\OperatorTok{+}\StringTok{ }\KeywordTok{table}\NormalTok{(condition)[[}\DecValTok{2}\NormalTok{]])}
\CommentTok{\# texture is missing in 80.5\% of cases}
\end{Highlighting}
\end{Shaded}

Here is a bit of the result:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# FALSE  TRUE }
\CommentTok{\# 17599  4260 }
\CommentTok{\# [1] "Clay"}
\CommentTok{\# }
\CommentTok{\# FALSE  TRUE }
\CommentTok{\# 17599  4260 }
\CommentTok{\# [1] "Sand"}
\CommentTok{\# }
\CommentTok{\# FALSE  TRUE }
\CommentTok{\# 17599  4260 }
\CommentTok{\# [1] "Silt"}
\end{Highlighting}
\end{Shaded}

The texture variables clay, sand and silt are not often measured in this
data set so we exclude them. We also exclude other variables that are
not commonly measured by soil scientists or not clearly defined:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{eusoil <{-}}\StringTok{ }\NormalTok{eusoil }\OperatorTok{\%>\%}\StringTok{ }\KeywordTok{select}\NormalTok{(}\OperatorTok{{-}}\NormalTok{Clay, }\OperatorTok{{-}}\NormalTok{Sand, }\OperatorTok{{-}}\NormalTok{Silt, }\OperatorTok{{-}}\NormalTok{EC, }\OperatorTok{{-}}\NormalTok{pH.CaCl2., }\OperatorTok{{-}}\NormalTok{Soil\_Stones, }\OperatorTok{{-}}\NormalTok{LC1\_Desc) }\OperatorTok{\%>\%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(OC, N, P, K, CaCO3, pH.H2O., Elevation, landuse)}
\end{Highlighting}
\end{Shaded}

What variables are left and how do they relate? We want to draw some
conclusions of what to include by looking at a correlation plot.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#\#\# variable selection III: influential variables \#\#\#\#}
\KeywordTok{names}\NormalTok{(eusoil)}
\CommentTok{\#\# a) numerical variables that correlate with organic carbon but not with each other}
\NormalTok{relationships <{-}}\StringTok{ }\KeywordTok{plot}\NormalTok{(eusoil[}\DecValTok{1}\OperatorTok{:}\DecValTok{2000}\NormalTok{,]) }\CommentTok{\# plotting the first 2000 observations}
\end{Highlighting}
\end{Shaded}

\includegraphics{report_files/figure-latex/unnamed-chunk-9-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{relationships}
\end{Highlighting}
\end{Shaded}

P (phosphorus) and K (potassium) show no clear relationship to organic
carbon so we will exclude them soon in the code below. CaCO3 and pH are
co-dependend so it will be enough to include one of them. Thus we are
keeping N (Nitrogen), pH and elevation in our analysis

There is also a categorical variable, land use, so we check whether it
influences organic carbon:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{qplot}\NormalTok{(landuse, OC, }\DataTypeTok{data =}\NormalTok{ eusoil, }\DataTypeTok{fill =}\NormalTok{ landuse) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom\_boxplot}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{ylab}\NormalTok{(}\StringTok{"organic carbon mg C / g soil"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{report_files/figure-latex/unnamed-chunk-10-1.pdf}

Organic carbon differs with land use so we keep it as a factor. Now that
the decision on the variables to consider has been made, we give out
some easier-to-type variable names and select the chosen variables from
the data set.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{eusoil <{-}}\StringTok{ }\NormalTok{eusoil }\OperatorTok{\%>\%}\StringTok{ }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{pH =}\NormalTok{ pH.H2O., }\DataTypeTok{elev =}\NormalTok{ Elevation) }\OperatorTok{\%>\%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(OC, N, P, pH, elev, landuse)}
\end{Highlighting}
\end{Shaded}

\hypertarget{ii-c-data-set-division-into-validation-train-and-test-set}{%
\subsection{(II c) Data set division into validation, train and test
set}\label{ii-c-data-set-division-into-validation-train-and-test-set}}

First, from our data set, a validation set of 10\% is taken which will
only be used after deciding on a model. The validation set is important
so that our model will not be fit to a specific data set. We keep a
large proportion of the data for model training. The training set will
be 80\% and the test set 20\% of the remaining data. We should choose a
split that allows lots of training but still a representative test set.
For reproducible results, we use the set.seed() function.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DataTypeTok{sample.kind =} \StringTok{"Rounding"}\NormalTok{)}
\NormalTok{valindex <{-}}\StringTok{ }\KeywordTok{createDataPartition}\NormalTok{(eusoil}\OperatorTok{$}\NormalTok{OC, }\DataTypeTok{p =} \FloatTok{0.1}\NormalTok{, }\DataTypeTok{list =}\NormalTok{ F)}
\NormalTok{temp <{-}}\StringTok{ }\NormalTok{eusoil[}\OperatorTok{{-}}\NormalTok{valindex,]}
\NormalTok{validation <{-}}\StringTok{ }\NormalTok{eusoil[valindex,]}

\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DataTypeTok{sample.kind =} \StringTok{"Rounding"}\NormalTok{)}
\NormalTok{testindex <{-}}\StringTok{ }\KeywordTok{createDataPartition}\NormalTok{(temp}\OperatorTok{$}\NormalTok{OC, }\DataTypeTok{p =} \FloatTok{0.2}\NormalTok{, }\DataTypeTok{list =}\NormalTok{ F)}
\NormalTok{trainset <{-}}\StringTok{ }\NormalTok{temp[}\OperatorTok{{-}}\NormalTok{testindex,]}
\NormalTok{testset <{-}}\StringTok{ }\NormalTok{temp[testindex,]}

\CommentTok{\# see how many observations are in each}
\KeywordTok{nrow}\NormalTok{(trainset); }\KeywordTok{nrow}\NormalTok{(testset); }\KeywordTok{nrow}\NormalTok{(validation)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 15735
\end{verbatim}

\begin{verbatim}
## [1] 3937
\end{verbatim}

\begin{verbatim}
## [1] 2187
\end{verbatim}

The split retains 2000 obervations for final validation set which should
be plenty.

\hypertarget{ii-d-rmse-function}{%
\subsection{(II d) RMSE function}\label{ii-d-rmse-function}}

A rooted mean square error (RMSE) function is used to evaluate the
performance of the models that will be set up. It can be viewed as the
typical error we make when predicting from a given model.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{RMSE <{-}}\StringTok{ }\ControlFlowTok{function}\NormalTok{(observed\_values, predicted\_values)\{}
  \KeywordTok{sqrt}\NormalTok{(}\KeywordTok{mean}\NormalTok{((observed\_values }\OperatorTok{{-}}\StringTok{ }\NormalTok{predicted\_values)}\OperatorTok{\^{}}\DecValTok{2}\NormalTok{))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{ii-e-reference-model}{%
\subsection{(II e) Reference model}\label{ii-e-reference-model}}

A reference model can be useful to evaluate how different models perform
compared to simply guessing the outcome. In guessing, we would take the
average of the observed carbon values.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#\#\# guessing model \#\#\#\#}
\NormalTok{mu <{-}}\StringTok{ }\KeywordTok{mean}\NormalTok{(trainset}\OperatorTok{$}\NormalTok{OC)}

\NormalTok{rmse\_mu <{-}}\StringTok{ }\KeywordTok{RMSE}\NormalTok{(testset}\OperatorTok{$}\NormalTok{OC, mu)}
\NormalTok{rmse\_mu}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 77.78776
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# create an RMSE table to always add the RMSEs}
\NormalTok{rmses <{-}}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{model =} \StringTok{"mean"}\NormalTok{, }\DataTypeTok{rmse =}\NormalTok{ rmse\_mu)}
\NormalTok{rmses}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   model     rmse
## 1  mean 77.78776
\end{verbatim}

We see that if we guess, we are typically \textasciitilde78 mg C / g
soil off the observed value. We will improve this prediction, first with
linear models but also with KNN and random forest algorithms.

\hypertarget{ii-f-linear-models}{%
\subsection{(II f) Linear models}\label{ii-f-linear-models}}

In the following, different linear models (LM) are set up, first with N
(nitrogen) as predictor, then adding pH, elevation and landuse. The full
code is present in the R script and not shown here as to not overload
the report, However, we show the LM which includes all variables and the
table of how RMSE impoved step by step when adding more variables.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#\#\# lm with N, pH, elevation, landuse \#\#\#\#}

\NormalTok{m\_all <{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(OC }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{., }\DataTypeTok{data =}\NormalTok{ trainset)}

\NormalTok{base <{-}}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(testset)}

\NormalTok{pred4 <{-}}\StringTok{ }\KeywordTok{predict}\NormalTok{(m\_all, base)}
\KeywordTok{head}\NormalTok{(pred4)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         7        12        16        28        29        38 
##  12.67697  72.41147  55.78709 188.79738  66.74575 168.52116
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{qplot}\NormalTok{(testset}\OperatorTok{$}\NormalTok{OC, pred4)}
\end{Highlighting}
\end{Shaded}

\includegraphics{report_files/figure-latex/unnamed-chunk-16-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rmse4 <{-}}\StringTok{ }\KeywordTok{RMSE}\NormalTok{(testset}\OperatorTok{$}\NormalTok{OC, pred4)}
\NormalTok{rmse4}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 30.81398
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rmses <{-}}\StringTok{ }\KeywordTok{rbind}\NormalTok{(rmses, }
               \KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{model =} \StringTok{"lm with all variables"}\NormalTok{, }\DataTypeTok{rmse =}\NormalTok{ rmse4))}
\NormalTok{rmses}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                    model     rmse
## 1                   mean 77.78776
## 2              lm with N 33.24694
## 3         lm with N + pH 32.60644
## 4 lm with N + pH + elev. 32.54013
## 5  lm with all variables 30.81398
\end{verbatim}

\newpage

\hypertarget{ii-g-knn-models}{%
\subsection{(II g) KNN models}\label{ii-g-knn-models}}

Since all variables appeared to improve the LM model above, we also
include these in a KNN model, which looks multidimensionally at the
nearest neighbors of an observation and predicts from there.

A first try with KNN including elevation yields a less-than-optimal
result (see RMSE table below). Another model which excludes elevation
worked well. I could not immediately detect the reason for this, but my
conclusion is that not every variable improves every type of model in
the same way. Generally, KNN performed well after improving on the
number of neighbors with a sapply() function.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#\#\# KNN [caret] all variables / excl. elevation \#\#\#\#}
\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(trainset)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 125.4392
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ks <{-}}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{30}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\NormalTok{ks}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# checking which is the optimal k}
\NormalTok{result <{-}}\StringTok{ }\KeywordTok{lapply}\NormalTok{(ks, }\ControlFlowTok{function}\NormalTok{(i)\{}
\NormalTok{  fit\_knn2 <{-}}\StringTok{ }\KeywordTok{knnreg}\NormalTok{(OC }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{N }\OperatorTok{+}\StringTok{ }\NormalTok{pH }\OperatorTok{+}\StringTok{ }\NormalTok{landuse, }\DataTypeTok{data =}\NormalTok{ trainset, }\DataTypeTok{k =}\NormalTok{ i)}
\NormalTok{  pred <{-}}\KeywordTok{predict}\NormalTok{(fit\_knn2, base)}
  \KeywordTok{RMSE}\NormalTok{(testset}\OperatorTok{$}\NormalTok{OC, pred)}
\NormalTok{\})}

\KeywordTok{plot}\NormalTok{(ks, result)}
\end{Highlighting}
\end{Shaded}

\includegraphics{report_files/figure-latex/unnamed-chunk-18-1.pdf}

The graph above shows different k's (numbers of neighbors considered)
and how the result (the RMSE) behaves with this. A k of 17 was used
because it yields the best result.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{best\_k <{-}}\StringTok{ }\NormalTok{ks[}\KeywordTok{which.min}\NormalTok{(}\KeywordTok{data.frame}\NormalTok{(result)[}\DecValTok{1}\NormalTok{,])] }\CommentTok{\#31}
\NormalTok{best\_k }\CommentTok{\# this is 17}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 17
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# using best k}

\NormalTok{fit\_knn2 <{-}}\StringTok{ }\KeywordTok{knnreg}\NormalTok{(OC }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{N }\OperatorTok{+}\StringTok{ }\NormalTok{pH }\OperatorTok{+}\StringTok{ }\NormalTok{landuse, }\DataTypeTok{data =}\NormalTok{ trainset, }\DataTypeTok{k =}\NormalTok{ best\_k)}
\NormalTok{pred7 <{-}}\KeywordTok{predict}\NormalTok{(fit\_knn2, base)}

\KeywordTok{qplot}\NormalTok{(testset}\OperatorTok{$}\NormalTok{OC, pred7)}
\end{Highlighting}
\end{Shaded}

\includegraphics{report_files/figure-latex/unnamed-chunk-19-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rmse7 <{-}}\StringTok{ }\KeywordTok{RMSE}\NormalTok{(testset}\OperatorTok{$}\NormalTok{OC, pred7)}
\NormalTok{rmse7}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 21.34432
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rmses <{-}}\StringTok{ }\KeywordTok{rbind}\NormalTok{(rmses, }
               \KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{model =} \StringTok{"knn excluding elev."}\NormalTok{, }\DataTypeTok{rmse =}\NormalTok{ rmse7))}
\NormalTok{rmses}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                    model     rmse
## 1                   mean 77.78776
## 2              lm with N 33.24694
## 3         lm with N + pH 32.60644
## 4 lm with N + pH + elev. 32.54013
## 5  lm with all variables 30.81398
## 6 knn with all variables 50.09455
## 7    knn excluding elev. 21.34432
\end{verbatim}

\newpage

\hypertarget{ii-h-random-forest-model}{%
\subsection{(II h) Random forest model}\label{ii-h-random-forest-model}}

A random forest model consists of many models (trees) that are combined
(to a forest) so the number of trees plays a role in the performance of
the model. The more trees the more exact the model usually is, but with
more trees it also takes more time to calculate. Here, I started with 10
trees, then tried 100, then 250 and then 500. The number of trees (ntree
= x) of 250 appeared to yield a good compromise between computing time
and performance. The best model includes all selected variables, unlike
KNN, which performed best without elevation.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}

\NormalTok{fit\_rf <{-}}\StringTok{ }\KeywordTok{randomForest}\NormalTok{(}
\NormalTok{  OC }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{., }\DataTypeTok{data =}\NormalTok{ trainset, }
  \DataTypeTok{ntree =} \DecValTok{250}
\NormalTok{)}

\CommentTok{\# going from 10 to 100 trees in the only{-}N model improved the RMSE by \textasciitilde{}0.4}
\CommentTok{\# and another 0.2 for 250 trees, hardly then anymore for 500 trees}

\NormalTok{pred8 <{-}}\StringTok{ }\KeywordTok{predict}\NormalTok{(fit\_rf, base)}
\KeywordTok{head}\NormalTok{(pred8)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         7        12        16        28        29        38 
##  21.22866  50.31972  65.58160 165.00924  46.67700 148.49321
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{qplot}\NormalTok{(testset}\OperatorTok{$}\NormalTok{OC, pred8)}
\end{Highlighting}
\end{Shaded}

\includegraphics{report_files/figure-latex/unnamed-chunk-20-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rmse8 <{-}}\StringTok{ }\KeywordTok{RMSE}\NormalTok{(testset}\OperatorTok{$}\NormalTok{OC, pred8)}
\NormalTok{rmse8}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 23.14774
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rmses <{-}}\StringTok{ }\KeywordTok{rbind}\NormalTok{(rmses, }
               \KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{model =} \StringTok{"rf with all variables"}\NormalTok{, }\DataTypeTok{rmse =}\NormalTok{ rmse8))}
\NormalTok{rmses}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                    model     rmse
## 1                   mean 77.78776
## 2              lm with N 33.24694
## 3         lm with N + pH 32.60644
## 4 lm with N + pH + elev. 32.54013
## 5  lm with all variables 30.81398
## 6 knn with all variables 50.09455
## 7    knn excluding elev. 21.34432
## 8  rf with all variables 23.14774
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# in this case all variables improve the model}
\end{Highlighting}
\end{Shaded}

\hypertarget{ii-i-ensemble-model-knn-and-random-forest}{%
\subsection{(II i) Ensemble model (KNN and random
forest)}\label{ii-i-ensemble-model-knn-and-random-forest}}

The two models with the best performance (lowest RMSE), were combined
into an ensemble, where the mean is taken from the prediction of both
models. This worked well as it further improved the RMSE:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred\_ensemble <{-}}\StringTok{ }\NormalTok{(pred7 }\OperatorTok{+}\StringTok{ }\NormalTok{pred8)}\OperatorTok{/}\DecValTok{2} \CommentTok{\# knn \& random forest }

\KeywordTok{qplot}\NormalTok{(testset}\OperatorTok{$}\NormalTok{OC, pred\_ensemble)}
\end{Highlighting}
\end{Shaded}

\includegraphics{report_files/figure-latex/unnamed-chunk-21-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rmse\_ens1 <{-}}\StringTok{ }\KeywordTok{RMSE}\NormalTok{(testset}\OperatorTok{$}\NormalTok{OC, pred\_ensemble)}
\NormalTok{rmse\_ens1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 20.86007
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rmses <{-}}\StringTok{ }\KeywordTok{rbind}\NormalTok{(rmses, }
               \KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{model =} \StringTok{"ensemble of knn \& rf"}\NormalTok{, }\DataTypeTok{rmse =}\NormalTok{ rmse\_ens1))}
\end{Highlighting}
\end{Shaded}

\newpage

\hypertarget{iii-results}{%
\section{(III) RESULTS}\label{iii-results}}

\hypertarget{iii-a-rmses-of-tested-models}{%
\subsection{(III a) RMSEs of tested
models}\label{iii-a-rmses-of-tested-models}}

As a result, we see an order of performance from best to least
performing model that is Ensemble (KNN \& random forest) \textgreater{}
KNN \textgreater{} random forest \textgreater{} linear model.

Here's the overview table:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rmses}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                    model     rmse
## 1                   mean 77.78776
## 2              lm with N 33.24694
## 3         lm with N + pH 32.60644
## 4 lm with N + pH + elev. 32.54013
## 5  lm with all variables 30.81398
## 6 knn with all variables 50.09455
## 7    knn excluding elev. 21.34432
## 8  rf with all variables 23.14774
## 9   ensemble of knn & rf 20.86007
\end{verbatim}

\hypertarget{iii-b-evaluation-of-best-model-on-validation-set}{%
\subsection{(III b) Evaluation of best model on validation
set}\label{iii-b-evaluation-of-best-model-on-validation-set}}

To finally evaluate performance of our model on an unseen dataset, we
now predict organic carbon in the validation set with the best two
models: KNN without elevation and random forest with all variables. It
is done as an ensemble.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# incorporate the mean prediction of knn and rf since they are the best ones}

\NormalTok{fin\_predict\_a <{-}}\StringTok{ }\KeywordTok{predict}\NormalTok{(fit\_knn2, validation)}
\NormalTok{fin\_predict\_b <{-}}\StringTok{ }\KeywordTok{predict}\NormalTok{(fit\_rf, validation)}

\NormalTok{fin\_predict <{-}}\StringTok{ }\NormalTok{(fin\_predict\_a }\OperatorTok{+}\StringTok{ }\NormalTok{fin\_predict\_b) }\OperatorTok{/}\StringTok{ }\DecValTok{2}

\KeywordTok{qplot}\NormalTok{(validation}\OperatorTok{$}\NormalTok{OC, fin\_predict, }\DataTypeTok{col =}\NormalTok{ validation}\OperatorTok{$}\NormalTok{landuse)}
\end{Highlighting}
\end{Shaded}

\includegraphics{report_files/figure-latex/unnamed-chunk-23-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fin\_rmse <{-}}\StringTok{ }\KeywordTok{RMSE}\NormalTok{(validation}\OperatorTok{$}\NormalTok{OC, fin\_predict)}

\NormalTok{rmses <{-}}\StringTok{ }\KeywordTok{rbind}\NormalTok{(rmses, }
               \KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{model =} \StringTok{"FINAL RMSE OVERALL"}\NormalTok{, }\DataTypeTok{rmse =}\NormalTok{ fin\_rmse))}
\end{Highlighting}
\end{Shaded}

\hypertarget{this-yields-the-final-rmse-our-typical-prediction-error-which-is}{%
\paragraph{This yields the final RMSE, our typical prediction error,
which
is:}\label{this-yields-the-final-rmse-our-typical-prediction-error-which-is}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fin\_rmse}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 19.01878
\end{verbatim}

\hypertarget{iii-b-model-performance-in-the-most-common-range-of-organic-carbon}{%
\section{(III b) Model performance in the most common range of organic
carbon}\label{iii-b-model-performance-in-the-most-common-range-of-organic-carbon}}

In the observation-prediction-graph above, we see that there are ranges
of organic where the model performes better than in other ranges. We can
divide the validation set into 3 ranges that appear to differ and
calculate model performance for each. This can be interesting in
practical regards as the user may be interested in certain soils that
lay within a specific range of organic carbon.

\hypertarget{iv-conclusion}{%
\section{(IV) CONCLUSION}\label{iv-conclusion}}

\hypertarget{iv-a-lessons-learned}{%
\subsection{(IV a) Lessons learned}\label{iv-a-lessons-learned}}

\hypertarget{iv-b-limitations}{%
\subsection{(IV b) Limitations}\label{iv-b-limitations}}

\hypertarget{iv-c-final-thoughts}{%
\subsection{(IV c) Final thoughts}\label{iv-c-final-thoughts}}

\newpage

\end{document}
